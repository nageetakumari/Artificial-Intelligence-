{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis with POS such that:\n",
    "    - we can look into the adjectives, adverbs\n",
    "# Dealing with RegEx for overcoming the problems of intensifiers:\n",
    "    - example: I have exam next week, Oh Shit!!!!!!!!!\n",
    "    - example: Don't tell me really???????????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [ ]\n",
    "with open('english-senitment-all-data.csv', 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        substrings = line.split(',')\n",
    "        lable = substrings[0]\n",
    "        sentence = ','.join(substrings[1:])\n",
    "        data.append((sentence.strip(), lable))\n",
    "print(data[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task to do\n",
    "\n",
    "read the file upload on the class room, prepare dataset and implement sentiment analysis as we did in perevious class. I.e, reading dictionary, tokenizing, looking-up, and evaluating scores.\n",
    "\n",
    "Time 15 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_lexica = dict()\n",
    "\n",
    "with open('afinn.csv', 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        word = line.strip().split(',')\n",
    "        sentiment_lexica[word[0]] = int(word[1])\n",
    "print(sentiment_lexica)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['not', 'dont', 'wont', 'do not', 'didnt', \"din't\", 'did not']\n"
     ]
    }
   ],
   "source": [
    "negation = \"not,dont,wont,do not,didnt,din't,did not\".split(',')\n",
    "print(negation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_analysis_1(sentence):\n",
    "    words = sentence.lower().split()\n",
    "    score = 0\n",
    "    for i,w in enumerate(words):\n",
    "        if w in sentiment_lexica:\n",
    "            if words[i-1] in negation:\n",
    "                score += sentiment_lexica[w] * -1\n",
    "            else:\n",
    "                score += sentiment_lexica[w]\n",
    "\n",
    "    # Evaluate score\n",
    "    if score == 0:\n",
    "        return (score, 0)\n",
    "    elif score > 0:\n",
    "        return (score, 1)\n",
    "    else:\n",
    "        return (score, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using NLTK PosTagger\n",
    "```\n",
    "CC | Coordinating conjunction |\n",
    "CD | Cardinal number |\n",
    "DT | Determiner |\n",
    "EX | Existential there |\n",
    "FW | Foreign word |\n",
    "IN | Preposition or subordinating conjunction |\n",
    "JJ | Adjective |\n",
    "JJR | Adjective, comparative |\n",
    "JJS | Adjective, superlative |\n",
    "LS | List item marker |\n",
    "MD | Modal |\n",
    "NN | Noun, singular or mass |\n",
    "NNS | Noun, plural |\n",
    "NNP | Proper noun, singular |\n",
    "NNPS | Proper noun, plural |\n",
    "PDT | Predeterminer |\n",
    "POS | Possessive ending |\n",
    "PRP | Personal pronoun |\n",
    "PRP$ | Possessive pronoun |\n",
    "RB | Adverb |\n",
    "RBR | Adverb, comparative |\n",
    "RBS | Adverb, superlative |\n",
    "RP | Particle |\n",
    "SYM | Symbol |\n",
    "TO | to |\n",
    "UH | Interjection |\n",
    "VB | Verb, base form |\n",
    "VBD | Verb, past tense |\n",
    "VBG | Verb, gerund or present participle |\n",
    "VBN | Verb, past participle |\n",
    "VBP | Verb, non-3rd person singular present |\n",
    "VBZ | Verb, 3rd person singular present |\n",
    "WDT | Wh-determiner |\n",
    "WP | Wh-pronoun |\n",
    "WP$ | Possessive wh-pronoun |\n",
    "WRB | Wh-adverb |\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/support/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'Oh ! that was the epic moment in the match'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Oh', 'UH'), ('!', '.'), ('that', 'WDT'), ('was', 'VBD'), ('the', 'DT'), ('epic', 'JJ'), ('moment', 'NN'), ('in', 'IN'), ('the', 'DT'), ('match', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "pos_tagged = pos_tag(sentence.split())\n",
    "print(pos_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_analysis_2(sentence):\n",
    "    words = sentence.lower().split()\n",
    "    tags = pos_tag(words)\n",
    "    score = 0\n",
    "    for i,w in enumerate(words):\n",
    "        is_emph = False\n",
    "        if w in sentiment_lexica:\n",
    "            if  tags[i][1] in {'JJ', 'JJR', 'JJS', 'RB', 'RBR', 'RBS'}:\n",
    "                score += 1\n",
    "            if words[i-1] in negation:\n",
    "                if is_emph:\n",
    "                    score += sentiment_lexica[w] * -1 \n",
    "                else:\n",
    "                    score += sentiment_lexica[w] * -1\n",
    "            else:\n",
    "                if is_emph:\n",
    "                    score += sentiment_lexica[w] + 1\n",
    "                else:\n",
    "                    score += sentiment_lexica[w]\n",
    "                    \n",
    "    if score == 0:\n",
    "        return (score, 0)\n",
    "    elif score > 0:\n",
    "        return (score, 1)\n",
    "    else:\n",
    "        return (score, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-3, -1)\n",
      "(-3, -1)\n"
     ]
    }
   ],
   "source": [
    "print(sentiment_analysis_1('I dont love chmeistry'))\n",
    "print(sentiment_analysis_2('I dont love chemistry'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-53-fc6ac1b5cc27>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-53-fc6ac1b5cc27>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    Oh Shit!!!!!!!!! -> Oh Shit !\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Oh Shit!!!!!!!!! -> Oh Shit !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
